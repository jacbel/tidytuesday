[["index.html", "Tidy Tuesday Contributions Intro", " Tidy Tuesday Contributions Jacob Bellmund Intro This page serves as documentation for Jacob Bellmund’s contributions to the Tidy Tuesday project. I will contribute as often as I can, but probably won’t be able to make it every week. You can find the Github Repo here. If you download the Github Repo, you should be able to run my code to reproduce or improve my contributions. If you have suggestions for improvements or any feedback, feel free to get in touch! If you don’t have the bookdown package installed, this should be the first thing you do. To install it, run from the R console: if(!require(&quot;bookdown&quot;)){install.packages(&quot;bookdown&quot;)} library(bookdown) After that, you can reproduce everything by running the command below from the R Studio console (make sure to have loaded the R project file). bookdown::render_book() You will be able to find the visualizations that are generated in the figures folder. # create folder for figure output if necessary using the here package if(!require(&quot;here&quot;)){install.packages(&quot;here&quot;)} library(here) if (!dir.exists(here(&quot;figures&quot;))){dir.create(here(&quot;figures&quot;))} "],["week-1.html", "Week 1 Data Data wrangling Home field advantage", " Week 1 The instructions for Week 1 of 2022 are short: This was really just a bring your own dataset week. Data Let’s look at some football (soccer) data from main European leagues. I use the data as distributed in the engsoccerdata package. First load the package after installing it if needed. if(!require(&quot;tidyverse&quot;)){install.packages(&quot;tidyverse&quot;)} library(tidyverse) if(!require(&quot;devtools&quot;)){install.packages(&quot;devtools&quot;)} library(devtools) if(!require(&quot;engsoccerdata&quot;)){install_github(&quot;jalapic/engsoccerdata&quot;)} library(engsoccerdata) if(!require(&quot;patchwork&quot;)){install.packages(&quot;patchwork&quot;)} library(patchwork) Load data from England, France, Germany, Italy and Spain. # load data df_eng &lt;- engsoccerdata::england df_fra &lt;- engsoccerdata::france df_ger &lt;- engsoccerdata::germany df_ita &lt;- engsoccerdata::italy df_esp &lt;- engsoccerdata::spain Data wrangling We want to add all data to one data frame. Some columns are missing, so let’s quickly compute them. # Germany is missing the columns for total goals, goal difference and result # Let&#39;s create these df_ger &lt;- df_ger %&gt;% mutate(totgoal = hgoal + vgoal, goaldif = hgoal + vgoal, result = case_when(hgoal &gt; vgoal ~ &quot;H&quot;, vgoal &gt; hgoal ~ &quot;A&quot;, hgoal == vgoal ~ &quot;D&quot;), country = &quot;Germany&quot;) df_ita &lt;- df_ita %&gt;% mutate(division = 1, totgoal = hgoal + vgoal, goaldif = hgoal + vgoal, result = case_when(hgoal &gt; vgoal ~ &quot;H&quot;, vgoal &gt; hgoal ~ &quot;A&quot;, hgoal == vgoal ~ &quot;D&quot;), country = &quot;Italy&quot;) df_esp &lt;- df_esp %&gt;% filter(round == &quot;league&quot;) %&gt;% select(-round, -group, -notes, -HT) %&gt;% mutate(division = 1, totgoal = hgoal + vgoal, goaldif = hgoal + vgoal, result = case_when(hgoal &gt; vgoal ~ &quot;H&quot;, vgoal &gt; hgoal ~ &quot;A&quot;, hgoal == vgoal ~ &quot;D&quot;), country = &quot;Spain&quot;) df_eng &lt;- df_eng %&gt;% mutate(country = &quot;England&quot;) df_fra &lt;- df_fra %&gt;% mutate(country = &quot;France&quot;, result = case_when(hgoal &gt; vgoal ~ &quot;H&quot;, vgoal &gt; hgoal ~ &quot;A&quot;, hgoal == vgoal ~ &quot;D&quot;) ) # build common data frame df &lt;- rbind(df_eng, df_ger, df_esp, df_ita, df_fra) Home field advantage All leagues First, let’s compute the proportions of home wins, away wins and draws irrespective of country (i.e. league). # result proportions by country df_win &lt;- df %&gt;% group_by(Season) %&gt;% summarise(home_win = sum(result == &quot;H&quot;)/n(), away_win = sum(result == &quot;A&quot;)/n(), draw = sum(result == &quot;D&quot;)/n(), .groups = &quot;drop&quot;) %&gt;% pivot_longer(cols = c(home_win, away_win, draw), names_to = &quot;result&quot;) # df for labelling df_label = df_win %&gt;% filter(Season == max(Season)) %&gt;% mutate(label = case_when(result == &quot;home_win&quot;~&quot;Home Win&quot;, result == &quot;away_win&quot;~&quot;Away Win&quot;, result == &quot;draw&quot;~&quot;Draw&quot;) ) Visualize percentages of home vs. away wins over time as a line graph. # plot as line graph p1 &lt;- ggplot(df_win %&gt;% filter(Season &gt; 1960, result != &quot;draw&quot;), aes(x = Season, y = value, group = result, color = result)) + geom_line() + geom_text(data = df_label %&gt;% filter(result != &quot;draw&quot;), aes(x = Season, y = value, label = label), hjust = -0.2, alpha = 1, fontface = &quot;bold&quot;) + xlim(c(1960, 2035)) + scale_color_manual(values = c(&quot;#ef8a62&quot;, &quot;#67a9cf&quot;)) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + ylab(element_blank()) + ggtitle(&quot;The decline of the home field advantage in top-tier European soccer&quot;) + annotate(geom = &quot;text&quot;, label = &quot;across 5 major European leagues&quot;, x=Inf, y=Inf, hjust = 1, vjust = 1, size = 11/.pt, face = &quot;bold&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;, text = element_text(size=10), plot.title = element_text(size = 14, face = &quot;bold&quot;, hjust = 0.5), axis.text = element_text(size=10)) ## Warning: Ignoring unknown parameters: face p1 Leagues separately Second, we repeat the above steps, but separately for each country. # result proportions by country df_win_country &lt;- df %&gt;% group_by(country, Season) %&gt;% summarise(home_win = sum(result == &quot;H&quot;)/n(), away_win = sum(result == &quot;A&quot;)/n(), draw = sum(result == &quot;D&quot;)/n(), .groups = &quot;drop&quot;) %&gt;% pivot_longer(cols = c(home_win, away_win, draw), names_to = &quot;result&quot;) # df for labelling df_label = df_win_country %&gt;% group_by(country) %&gt;% filter(Season == max(Season)) %&gt;% mutate(label = case_when(result == &quot;home_win&quot;~&quot;Home Win&quot;, result == &quot;away_win&quot;~&quot;Away Win&quot;, result == &quot;draw&quot;~&quot;Draw&quot;) ) Make a line plot with one facet per country # plot as line graph with one facet per country p2 &lt;- ggplot(df_win_country %&gt;% filter(Season &gt; 1960, result != &quot;draw&quot;), aes(x = Season, y = value, group = result, color = result)) + geom_line() + #geom_text(data = df_label %&gt;% filter(result != &quot;draw&quot;), # aes(x = Season, y = value, label = label), # hjust = -0.2, alpha = 1, fontface = &quot;bold&quot;) + #xlim(c(1960, 2026)) + scale_color_manual(values = c(&quot;#ef8a62&quot;, &quot;#67a9cf&quot;)) + scale_x_continuous(breaks = seq(1970, 2010, 20), minor_breaks = seq(1960, 2020, 20)) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + ylab(element_blank()) + facet_wrap(~country, nrow = 1) + labs(caption = &quot;Visualization by Jacob Bellmund, licensed under CC BY 4.0.\\nData based on: James P. Curley (2016). engsoccerdata: English Soccer Data 1871-2016. v. 0.1.7&quot;)+ theme_minimal() + theme(legend.position = &quot;none&quot;, text = element_text(size=10), axis.text = element_text(size=10), strip.text = element_text(size = 11), plot.caption = element_text(size=6)) p2 Visualization dsgn &lt;- &quot; ABBBC DDDDD &quot; p &lt;- plot_spacer() + p1 + plot_spacer() + p2 + plot_layout(design = dsgn, guides = &quot;keep&quot;) p ggsave(filename = here(&quot;figures&quot;, &quot;bellmund_tidytuesday_2022_wk01.png&quot;), plot = p, width = 10, height = 6) Here is the final visualization with the correct aspect ratio: "],["week-3.html", "Week 3 Data Data wrangling Phrases used to describe chocolate", " Week 3 The data for Week 3 of 2022 are about chocolate. Data The data this week comes from Flavors of Cacao by way of Georgios and Kelsey. First load the package after installing it if needed. if(!require(&quot;tidyverse&quot;)){install.packages(&quot;tidyverse&quot;)} library(tidyverse) if(!require(&quot;patchwork&quot;)){install.packages(&quot;patchwork&quot;)} library(patchwork) if(!require(&quot;ggwordcloud&quot;)){install.packages(&quot;ggwordcloud&quot;)} library(&quot;ggwordcloud&quot;) Load data from the github repo. # read data chocolate &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv&#39;) ## Rows: 2530 Columns: 10 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (7): company_manufacturer, company_location, country_of_bean_origin, specific_bean_origin_or_bar_name, cocoa_percent, ingredients, most_memor... ## dbl (3): ref, review_date, rating ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Data wrangling # make percentage cocoa a number chocolate &lt;- chocolate %&gt;% mutate(cocoa_percent = parse_number(cocoa_percent)) # split the memorable characteristics into individual phrases and make a long data frame (1 line per characteristic) chocolate_long &lt;- chocolate %&gt;% mutate(most_memorable_characteristics = str_split(most_memorable_characteristics, pattern = &quot;, &quot;)) %&gt;% unnest(everything()) %&gt;% mutate(most_memorable_characteristics = str_split(most_memorable_characteristics, pattern = &quot;,&quot;)) %&gt;% # repeat because sometimes no space unnest(everything()) Phrases used to describe chocolate To start, I will make my first ever wordcloud, showing the most frequent characteristics for the different chocolates in the dataset. # count number of times a phrase is used chocolate_sum &lt;- chocolate_long %&gt;% group_by(most_memorable_characteristics) %&gt;% count() %&gt;% arrange(desc(n)) # add random rotation to some words chocolate_sum &lt;- chocolate_sum %&gt;% mutate(angle = sample(-90:90,size=1) * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) # word cloud p1 &lt;- ggplot(chocolate_sum[1:100,], aes(label = most_memorable_characteristics, size = n, angle = angle)) + geom_text_wordcloud(family=&quot;Roboto&quot;, eccentricity = 1, color = &quot;white&quot;) + theme_minimal() + theme(plot.background = element_rect(fill = &quot;#B19E85&quot;)) p1 Phrases used to describe chocolate by percentage of cocoa Now, let’s do the same for different percentages of cocoa. # count number of times a phrase is used chocolate_sum &lt;- chocolate_long %&gt;% mutate(cocoa_group = case_when(cocoa_percent&lt;60 ~ &quot;&lt;60% cocoa&quot;, cocoa_percent&gt;59 &amp; cocoa_percent &lt;= 75 ~ &quot;60-75% cocoa&quot;, cocoa_percent&gt;75 &amp; cocoa_percent &lt;= 90 ~ &quot;76-90% cocoa&quot;, cocoa_percent&gt;90 ~ &quot;&gt;90% cocoa&quot;), cocoa_group = factor(cocoa_group, levels = c(&quot;&lt;60% cocoa&quot;, &quot;60-75% cocoa&quot;, &quot;76-90% cocoa&quot;, &quot;&gt;90% cocoa&quot;)) ) %&gt;% group_by(cocoa_group, most_memorable_characteristics) %&gt;% count() %&gt;% ungroup() %&gt;% group_by(cocoa_group) %&gt;% mutate(prop = n/sum(n), n_group = n()) %&gt;% slice_max(order_by = n, n = 20, with_ties = FALSE) # add random rotation to some words chocolate_sum &lt;- chocolate_sum %&gt;% mutate(angle = sample(-90:90,size=1) * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) # word cloud for each facet (do in loop because facet backgrounds cannot be altered individually) cocoa_colors &lt;- c(&quot;#624226&quot;, &quot;#49311d&quot;, &quot;#312113&quot;, &quot;#18100a&quot;) titles = c(&quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;Most frequent characteristics of chocolate by amount of cocoa &quot;) captions = c(&quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;Visualization by Jacob Bellmund, licensed under CC BY 4.0.\\nData based on: http://flavorsofcacao.com/chocolate_database.html&quot;) p2 &lt;- list() for (i in 1:length(levels(chocolate_sum$cocoa_group))) { i_level &lt;- levels(chocolate_sum$cocoa_group)[i] p2[[i]] &lt;- ggplot(chocolate_sum %&gt;% filter(cocoa_group == i_level), aes(label = most_memorable_characteristics, size = prop, angle = angle)) + geom_text_wordcloud(family=&quot;Roboto&quot;, eccentricity = 1, color = &quot;white&quot;) + facet_wrap(~cocoa_group, nrow = 1, strip.position = &quot;bottom&quot;) + labs(caption = captions[i], title= titles[i]) + theme_minimal() + theme(plot.background = element_rect(fill=cocoa_colors[i]), strip.text = element_text(face = &quot;bold&quot;, size = 14, color = &quot;white&quot;, family = &quot;Roboto&quot;), plot.caption = element_text(color = &quot;white&quot;, size = 6, family = &quot;Roboto&quot;), plot.title = element_text(color = &quot;white&quot;, face = &quot;bold&quot;, size = 18, family = &quot;Roboto&quot;, hjust = 1)) print(p2[[i]]) } Visualization dsgn &lt;- &quot;ABCD&quot; p &lt;- p2[[1]] + p2[[2]] + p2[[3]] + p2[[4]] + plot_layout(design = dsgn, guides = &quot;keep&quot;) p ## Warning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, : One word could not fit on page. It has been placed at its original ## position. ggsave(filename = here(&quot;figures&quot;, &quot;bellmund_tidytuesday_2022_wk03.png&quot;), plot = p, width = 8, height = 5.5) Here is the final visualization with the correct aspect ratio: "],["week-7.html", "Week 7 Data Data wrangling Recreate the plot", " Week 7 Week 7 of 2022 is part of the Du Bois Challenge. About W.E.B. Du Bois William Edward Burghardt Du Bois (/djuːˈbɔɪs/ dew-BOYSS;[1][2] February 23, 1868 – August 27, 1963) was an American sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer and editor. Born in Great Barrington, Massachusetts, Du Bois grew up in a relatively tolerant and integrated community, and after completing graduate work at the University of Berlin and Harvard, where he was the first African American to earn a doctorate, he became a professor of history, sociology and economics at Atlanta University. Du Bois was one of the founders of the National Association for the Advancement of Colored People (NAACP) in 1909. Source: Wikipedia DuBois Challenge The goal of the challenge is to celebrate the data visualization legacy of W.E.B Du Bois by recreating the visualizations from the 1900 Paris Exposition using modern tools. I will take on Challenge 06, which is to recreate Plate 14. The target image is shown below: Data First load the tidyverse package after installing it if needed. if(!require(&quot;tidyverse&quot;)){install.packages(&quot;tidyverse&quot;)} library(tidyverse) Load data from the github repo. # read data illiteracy &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/ajstarks/dubois-data-portraits/master/challenge/2022/challenge06/data.csv&#39;) ## Rows: 5 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (2): Date, Iliteracy Rate ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Data wrangling The goal is to re-create the chart using geom_polygon to get the diagonal edge between the horizontal and vertical rectangles. For this, we need to do some data wrangling with the aim of calculating the vertices of the polygons. # To match the width of the polygons, we need to take the axes ranges of the final # plot as well as the aspect ratio into account. # We use these values to calculate how far the polygons should extend beyond the original values. y_range &lt;- 1940-1858 # values via: range(ggplot_build(p)$layout$panel_scales_y[[1]]$range$range) x_range &lt;- 101-48 # values via: range(ggplot_build(p)$layout$panel_scales_x[[1]]$range$range) asp_ratio &lt;- 2 x_extend &lt;- 2 y_extend &lt;- x_extend/x_range * y_range /asp_ratio illiteracy_long &lt;- illiteracy %&gt;% rename(IlliteracyRate = `Iliteracy Rate`) %&gt;% # create long data frame from input data with four entries per year. slice(rep(1:n(), each=4)) %&gt;% # add polygon vertices for horizontal and vertical polygons mutate(date_high_low = rep(rep(c(&quot;high&quot;, &quot;low&quot;), each = 2), times = 5), rate_high_low = rep(c(&quot;high&quot;, &quot;low&quot;), times = 10), DatePolyVert = case_when(date_high_low == &quot;high&quot; ~ Date - y_extend, date_high_low == &quot;low&quot; ~ 1940), DatePolyHori = case_when(date_high_low == &quot;high&quot; ~ Date + y_extend , date_high_low == &quot;low&quot; ~ Date - y_extend), RatePolyHori = case_when(rate_high_low == &quot;high&quot; ~ 104, rate_high_low == &quot;low&quot; ~ IlliteracyRate - x_extend), RatePolyVert = case_when(rate_high_low == &quot;high&quot; ~ IlliteracyRate + x_extend, rate_high_low == &quot;low&quot; ~ IlliteracyRate - x_extend), RatePolyHori = if_else(date_high_low == &quot;high&quot; &amp; rate_high_low == &quot;low&quot;, # to get the diagonal edge IlliteracyRate + x_extend, RatePolyHori), index = rep(c(1, 2, 4, 3), times = 5)) %&gt;% arrange(index) Recreate the plot p &lt;- ggplot(illiteracy_long, aes(x = RatePolyVert, y = DatePolyVert, group = Date)) + geom_polygon(fill = &quot;black&quot;, color = &quot;black&quot;) + geom_polygon(data = illiteracy_long, aes(x = RatePolyHori, y = DatePolyHori, group = Date), fill = &quot;white&quot;, color = &quot;black&quot;) + scale_y_reverse(breaks = illiteracy_long$Date, labels = illiteracy_long$Date, expand = c(0, 0)) + scale_x_reverse(breaks = illiteracy_long$IlliteracyRate, labels = sprintf(&quot;%s%%&quot;, as.character(illiteracy_long$IlliteracyRate)), expand = c(0, 0)) + ylab(element_blank()) + xlab(element_blank()) + ggtitle(&quot;ILLITERACY.&quot;)+ theme_minimal() + theme(aspect.ratio = asp_ratio, panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(family = &quot;Courier&quot;), plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;), plot.background = element_rect(fill = &quot;#E3D2C4&quot;, color = NA)) p ggsave(filename = here(&quot;figures&quot;, &quot;bellmund_tidytuesday_2022_wk07.png&quot;), plot = p, width = 3, height = 6) Here is the final visualization with the correct aspect ratio: "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
